---
layout:   page
title:       "å¦‚ä½•åˆ©ç”¨OpenAIçš„å‡½æ•°è°ƒç”¨ç‰¹æ€§"
subtitle:    ""
description: ""
date:        2023-07-26
author:   "aiqiu"
#image:       "https://golearning.oss-cn-shanghai.aliyuncs.com/202304161638319.png"
categories:  ["Geeks"]
summary:     "åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æ·±å…¥æ¢ç´¢äº†OpenAIçš„å‡½æ•°è°ƒç”¨ç‰¹æ€§ï¼Œå¹¶è§£æäº†å…¶åœ¨å®ç°ç»“æ„åŒ–æ•°æ®ç”Ÿæˆä¸­çš„å·¨å¤§ä»·å€¼ã€‚è™½ç„¶æˆ‘ä»¬é€šå¸¸è®¤ä¸ºç”Ÿæˆæ¨¡å‹äº§ç”Ÿçš„æ•°æ®æ˜¯æ— ç»“æ„çš„ï¼Œä½†åœ¨æ–‡ç« ä¸­è¯æ˜ï¼Œå€ŸåŠ©å‡½æ•°è°ƒç”¨ç‰¹æ€§ï¼Œæˆ‘ä»¬å®Œå…¨æœ‰å¯èƒ½åˆ›å»ºå‡ºç»“æ„åŒ–çš„æ•°æ®ã€‚"
published: true
---
# å¦‚ä½•åˆ©ç”¨OpenAIçš„å‡½æ•°è°ƒç”¨ç‰¹æ€§

## å‡½æ•°è°ƒç”¨èƒ½å®ç°å“ªäº›åŠŸèƒ½ï¼Ÿ

ç®€å•æ¥è¯´ï¼Œå‡½æ•°è°ƒç”¨åŠŸèƒ½å¯ä»¥åŠ©ä½ åœ¨è¯·æ±‚æ–¹æ³•æ—¶æ„å»º**ç»“æ„åŒ–çš„æ•°æ®**ã€‚å› ä¸ºç”Ÿæˆæ¨¡å‹çš„ç‰¹æ€§ï¼Œå®ƒäº§ç”Ÿçš„æ•°æ®å¾€å¾€æ˜¯æ— ç»“æ„çš„ï¼Œå³ä½¿åœ¨æç¤º(prompt)ä¸­æŒ‡å®šäº†è¾“å‡ºæ ¼å¼ï¼Œä½†å®é™…è¾“å‡ºçš„ç»“æœå¾€å¾€åç¦»é¢„æœŸã€‚

å¦‚æœä½ æ›¾ç»ä½¿ç”¨è¿‡Langchainï¼Œé‚£ä¹ˆä½ ä¸€å®šçŸ¥é“å…¶ä¸­æœ‰ä¸€ä¸ªå«åš`OutputParser`çš„æ¨¡å—ï¼Œè¿™ä¸ªæ¨¡å—ä¸­å®šä¹‰äº†è®¸å¤šç”¨äºå¿«é€Ÿç»“æ„åŒ–æ•°æ®çš„å·¥å…·ã€‚

![](https://golearning.oss-cn-shanghai.aliyuncs.com/202307250724965.png)

ç„¶è€Œï¼Œé¢å¯¹å¤§è§„æ¨¡çš„æ¨¡å‹ï¼Œè¿™äº›å·¥å…·å¹¶ä¸æ€»æ˜¯é‚£ä¹ˆæœ‰æ•ˆã€‚å› ä¸ºæ¨¡å‹çš„è¾“å‡ºç»“æœéš¾ä»¥é¢„æµ‹ï¼Œè¿™ä½¿å¾—åœ¨ä¸€äº›å¤æ‚åœºæ™¯ä¸‹ï¼Œæ¨¡å‹è¾“å‡ºçš„ç»“æœæ€»æ˜¯æ— æ³•è¢«æ­£ç¡®è§£æã€‚å³ä½¿æ˜¯ä½¿ç”¨äº†Langchainä¸­çš„`OutputFixingParser`ï¼Œä¹Ÿéš¾ä»¥è®©æ•´ä¸ªæµç¨‹å˜å¾—æµç•…ã€‚

å› æ­¤ï¼Œæˆ‘ä»¬ä»ç„¶éœ€è¦å›å½’åˆ°OpenAIå®˜æ–¹æ¨å‡ºçš„`å‡½æ•°è°ƒç”¨`ç‰¹æ€§ã€‚åœ¨å®˜æ–¹æä¾›çš„ä¸€ä¸ªç¤ºä¾‹ä¸­ï¼Œå®ƒä½¿ç”¨`function calling`è®©GPTæ¨¡å‹**æå–è‡ªç„¶è¯­è¨€ä¸­å¯ç”¨äºå‡½æ•°è°ƒç”¨çš„ä¿¡æ¯**ï¼Œç„¶ååˆ©ç”¨ç¬¬ä¸‰æ–¹æ¥å£è·å–å®æ—¶ä¿¡æ¯ï¼Œæœ€åç”Ÿæˆä¸€ä¸ªå…¨æ–°çš„æ€»ç»“ã€‚

![](https://golearning.oss-cn-shanghai.aliyuncs.com/202307250731130.png)

## å¦‚ä½•ä½¿ç”¨å‡½æ•°è°ƒç”¨ä»¥åŠå…¶å·¥ä½œåŸç†ï¼Ÿ

æ¥ä¸‹æ¥ï¼Œè®©æˆ‘ä»¬å€ŸåŠ©å®˜æ–¹çš„ç¤ºä¾‹æ¥è§£æä¸€ä¸‹å¦‚ä½•ä½¿ç”¨`function calling`è¿™ä¸ªç‰¹æ€§ï¼Œä»¥åŠå®ƒç©¶ç«Ÿæ˜¯å¦‚ä½•è¿ä½œçš„ã€‚

### ç¬¬ä¸€æ­¥ï¼šæºå¸¦å‡½æ•°è°ƒç”¨å»è¯·æ±‚GPTæ¥å£

é¦–å…ˆï¼Œä½ éœ€è¦æŠŠä¸€ä¸ªé—®é¢˜å’Œå‡½æ•°è°ƒç”¨ä¸€èµ·ï¼Œä½œä¸ºè¯·æ±‚æäº¤åˆ°GPTçš„æ¥å£ã€‚

```python
messages = [{"role": "user", "content": "What's the weather like in Boston?"}]
functions = [
        {
            "name": "get_current_weather",
            "description": "Get the current weather in a given location",
            "parameters": {
                "type": "object",
                "properties": {
                    "location": {
                        "type": "string",
                        "description": "The city and state, e.g. San Francisco, CA",
                    },
                    "unit": {"type": "string", "enum": ["celsius", "fahrenheit"]},
                },
                "required": ["location"],
            },
        }
    ]
response = openai.ChatCompletion.create(
        model="gpt-3.5-turbo-0613",
        messages=messages,
        functions=functions,
        function_call="auto",  # auto is default, but we'll be explicit
    )
response_message = response["choices"][0]["message"]

"""
è¾“å‡ºï¼š
 <OpenAIObject at 0x7a90d69f1620> JSON: {
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "get_current_weather",
    "arguments": "{\n  \"location\": \"Boston, MA\"\n}"
  }
}
 """
```

åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œå…ˆæ˜¯å®šä¹‰äº†ä¸€ä¸ªé—®é¢˜ï¼š `What's the weather like in Boston?`, è¿™ä¸ªæ˜¯æˆ‘ä»¬æƒ³è¦å›ç­”çš„é—®é¢˜ï¼Œå…¶ä¸­`Boston`æ˜¯é—®é¢˜ä¸­çš„åœ°åï¼Œ`weather`æ˜¯æˆ‘ä»¬æƒ³è¦çŸ¥é“çš„ä¿¡æ¯ã€‚åœ¨ä¸‹é¢çš„functionä¸­ï¼Œæˆ‘ä»¬å®šä¹‰äº†ä¸€ä¸ªfunctionæ¥æŒ‡æ˜æˆ‘ä»¬åœ¨è·å–ä¸‰æ–¹çš„apiæ—¶éœ€è¦å“ªäº›å‚æ•°ï¼Œè¿›è€Œè®©gptçŸ¥é“å®ƒåº”è¯¥ä»`What's the weather like in Boston?` è¿™å¥è¯ä¸­æå–ä»€ä¹ˆæ ·çš„ä¿¡æ¯ï¼Œä»¥åŠä»€ä¹ˆæ ¼å¼çš„ä¿¡æ¯ã€‚

### ç¬¬äºŒæ­¥ï¼šæ‹¿ç€è§£æå‡ºæ¥çš„ä¿¡æ¯è¯·æ±‚æ¥å£

```
import json
# è¿™æ˜¯ä¸€ä¸ªè™šå‡çš„å‡½æ•°ï¼Œç”¨æ¥æ¨¡æ‹Ÿä¸‰æ–¹æ¥å£çš„è¿”å›å€¼
def get_current_weather(location, unit="fahrenheit"):
    """Get the current weather in a given location"""
    weather_info = {
        "location": location,
        "temperature": "72",
        "unit": unit,
        "forecast": ["sunny", "windy"],
    }
    return json.dumps(weather_info)

if response_message.get("function_call"):
        # Step 3: call the function
        # Note: the JSON response may not always be valid; be sure to handle errors
        available_functions = {
            "get_current_weather": get_current_weather,
        }  # only one function in this example, but you can have multiple
        function_name = response_message["function_call"]["name"]
        fuction_to_call = available_functions[function_name]
        function_args = json.loads(response_message["function_call"]["arguments"])
        function_response = fuction_to_call(
            location=function_args.get("location"),
            unit=function_args.get("unit"),
        )
"""
è¾“å‡ºçš„function_response:
{"location": "Boston, MA", "temperature": "72", "unit": null, "forecast": ["sunny", "windy"]}
"""
```

åœ¨è¿™ä¸€æ­¥ä¸­ï¼Œæˆ‘ä»¬é€šè¿‡`        function_name = response_message["function_call"]["name"]` è¿™ä¸ªæ¥è·å–åˆ°äº†gptæ¨¡å‹è§£æå‡ºçš„å‡½æ•°åï¼Œå› ä¸ºåœ¨æ›´å¤æ‚çš„åœºæ™¯ä¸­ï¼Œæˆ‘ä»¬å¯èƒ½ä¸€æ¬¡æ€§è®©gptè§£ææ›´å¤šçš„æ–¹æ³•ï¼Œå› æ­¤æˆ‘ä»¬éœ€è¦è·å–åˆ°æ‰€æœ‰çš„å‡½æ•°åã€‚

æ¥ç€æˆ‘ä»¬åˆé€šè¿‡`response_message["function_call"]["arguments"]`è¿™ä¸ªè·å–åˆ°äº†è§£æå‡ºæ¥çš„å‚æ•°ã€‚è¿™è¾¹çš„å‚æ•°å…¶å®å°±gpté€šè¿‡æˆ‘ä»¬çš„é—®é¢˜æå–åˆ°çš„èƒ½å¤Ÿè¢«ç”¨åˆ°`get_current_weather`è¿™ä¸ªå‡½æ•°ä¸­ä½œä¸ºå‚æ•°çš„å†…å®¹ã€‚æ¯”å¦‚ç°åœ¨æˆ‘ä»¬éœ€è¦çš„ä¸¤ä¸ªå‚æ•°æ˜¯`location`å’Œ`unit`, gptå°±ä¼šæ ¹æ®ç°æœ‰çš„è¿™ä¸ªé—®é¢˜æ¥æå–æ˜¯`localtion`å’Œ`unit`æ„æ€çš„ä¿¡æ¯ã€‚

### ç¬¬ä¸‰æ­¥ç”Ÿæˆä¸€ä¸ªsummary

```
 messages.append(response_message)  # extend conversation with assistant's reply
        messages.append(
            {
                "role": "function",
                "name": function_name,
                "content": function_response,
            }
        )  # extend conversation with function response
        second_response = openai.ChatCompletion.create(
            model="gpt-3.5-turbo-0613",
            messages=messages,
        )  # get a new response from GPT where it can see the function response
```

åœ¨æœ€åä¸€æ­¥åªæ˜¯å•çº¯çš„æ ¹æ®ä¸Šä¸‹æ–‡ä¿¡æ¯ç”Ÿæˆä¸€ä¸ªæ–°çš„å¥å­ï¼Œå…¶å®æ²¡æœ‰ä»€ä¹ˆæ›´å¤šçš„ä¿¡æ¯ã€‚

æ¥ä¸‹æ¥æˆ‘ä»¬é€šè¿‡å¦ä¸€ä¸ªç¨å¾®å¤æ‚ä¸€ç‚¹ç‚¹çš„æ¡ˆä¾‹å†æ¥è§£é‡Šä¸‹`function calling`çš„ç”¨æ³•



## ä¸¾ä¸ªæ —å­ è®©GPTæœºå™¨ç¿»è¯‘

ç°åœ¨æˆ‘ä»¬æƒ³è®©GPTå¸®æˆ‘åšä¸€ä¸ªç¿»è¯‘çš„åŠŸèƒ½ï¼Œå¹¶ä¸”ç¿»è¯‘çš„ä¿¡æ¯å¯ä»¥ç»“æ„åŒ–çš„è¾“å‡ºï¼Œäºæ˜¯æˆ‘å†™äº†è¿™ä¹ˆä¸€ä¸ªprompt:

```python
prompt_template = """
 Now you have to translate the following text into {lang}:
    ### Text to translate:
    {text}
    ### Target language:
    {lang}
    ### Output format:
    your translation should in the following format:
    {{'res': 'your translation'}}
"""
```

å…¶å®ï¼Œåœ¨å¤§éƒ¨åˆ†æƒ…å†µåªä¸‹ï¼Œè¿™ä¸ªpromptå°±å·²ç»å¯ä»¥è¾“å‡ºä¸€ä»½ç»“æ„åŒ–çš„æ•°æ®äº†ï¼Œä½†æ˜¯åœ¨å¤æ‚åœºæ™¯æ¯”å¦‚ä½ çš„æ–‡æœ¬è¾ƒé•¿ï¼Œæˆ–è€…å°è¯•ç¿»è¯‘å¤§é‡æ–‡æœ¬çš„æ—¶å€™ï¼Œæ¨¡å‹æ€»ä¼šå‡ºç°ä¸€äº›é¢å¤–çš„ä¿¡æ¯ï¼Œä¸ä»…ä»…åªæœ‰ä½ æƒ³è¦çš„è¿™ä¸ªjsonæ ¼å¼ï¼Œå¯èƒ½è¿˜æœ‰å…¶ä»–è¿å¸¦å‡ºæ¥çš„è¾“å‡ºã€‚

ç°åœ¨æˆ‘æƒ³è¦åšçš„æ˜¯ï¼Œä½¿ç”¨`function calling` æ¥è§£ææˆ‘ä»¬çš„è¾“å‡ºï¼Œæˆ‘åªæƒ³è¦æœ€åçš„ç¿»è¯‘ç»“æœã€‚æ¯”è¾ƒçœé’±ä½†æ˜¯è´¹åŠ›çš„æ–¹æ³•å°±æ˜¯æˆ‘ç›´æ¥æå–æœ€ç»ˆè¿”å›æ•°æ®ä¸­çš„ `{res : xxx}` è¿™ä¸ªå­—ç¬¦ä¸²ï¼Œå¹¶è·å¾—å®ƒçš„å€¼ã€‚ ä½†æ˜¯åœ¨è¿™é‡Œæˆ‘ä»¬è¿˜æ˜¯æ‰“ç®—ä½¿ç”¨`function calling`æ¥å¸®æˆ‘ä»¬è§£æè¿™ä¸ªæ•°æ®ã€‚

ç°åœ¨æˆ‘ä»¬çš„ç¿»è¯‘çš„æ‰§è¡Œæ˜¯è¿™æ ·çš„ï¼š

```
text = 'Collection of Open Source Projects Related to GPTï¼ŒGPTç›¸å…³å¼€æºé¡¹ç›®åˆé›†ğŸš€ã€ç²¾é€‰ğŸ”¥ğŸ”¥'
lang = 'en'

prompt = prompt_template.format(text=text, lang=lang)
# completionæ˜¯æˆ‘ä»¬å°è£…çš„ä¸€ä¸ªè½¬å‘openaiè¯·æ±‚çš„å‡½æ•°ï¼Œæ²¡æœ‰ä»€ä¹ˆç‰¹åˆ«çš„å®ç°
response = completion(model_name="gpt-3.5-turbo-0613", prompt=prompt)

response.content
"""
è¾“å‡ºï¼š
{'res': 'Collection of Open Source Projects Related to GPT, Compilation of open source projects related to GPT ğŸš€, selected ğŸ”¥ğŸ”¥'}
"""
```

ç°åœ¨æˆ‘ä»¬å®šä¹‰ä¸€ä¸ª`ResponseSchema`æ¥ä»£è¡¨è¿™ä¸ªè¾“å‡ºã€‚ å› ä¸ºåœ¨å¤æ‚çš„ç”Ÿäº§åœºæ™¯ä¸­ï¼Œæˆ‘ä»¬å¾€å¾€éœ€è¦è§£æçš„å¯¹è±¡æ˜¯å¾ˆå¤æ‚çš„ï¼Œæ˜¯æœ‰å¤šä¸ªå­—æ®µä»¥åŠä¸åŒç±»å‹çš„ï¼Œæˆ‘ä»¬ä¸å¯èƒ½åƒå®˜æ–¹çš„ä¾‹å­ä¸€æ ·æ‰‹åŠ¨å»å»å†™æ¯ä¸€ä¸ªparametersã€‚

åœ¨è¿™é‡Œæˆ‘ä½¿ç”¨äº†pythonçš„`pydantic`åŒ…æ¥å®ç°è¿™ä¹ˆä¸€ä¸ªåŠŸèƒ½ã€‚

```python
from pydantic import BaseModel, Field
import json

class ResponseSchema(BaseModel):
    result: str = Field(..., description="the translated value")

    @classmethod
    def schema(cls, by_alias=True):
        schema = super().schema(by_alias)
        schema.pop('title', None)
        return schema
    @classmethod
    def schema_json(cls, by_alias=True, **dumps_kwargs):

        schema_str = json.dumps(cls.schema(by_alias), **dumps_kwargs)
        return json.loads(schema_str)
```

åœ¨è¿™é‡Œæˆ‘æ‰‹åŠ¨çš„å®ç°äº†`schema`å’Œ `schema_json` å‡½æ•°ï¼Œå› ä¸º `pydantic`çš„æ¨¡å‹ç±»æ€»ä¼šè‡ªå¸¦ä¸€ä¸ª`title`çš„å±æ€§ï¼Œè¿™ä¸ªå±æ€§å¾ˆå¤§ç¨‹åº¦ä¸Šä¼šå½±å“GPTå¯¹æˆ‘ä»¬æœ€ç»ˆæƒ³è¦çš„è¾“å‡ºçš„ç†è§£ã€‚

æˆ‘ä»¬æ‰§è¡Œ`ResponseSchema.schema_json()`å°±å¯ä»¥è·å–åˆ°å’Œä¸Šé¢å®˜æ–¹ä¾‹å­ä¸€æ ·çš„ä¸€ä¸ªå…³äºå­—æ®µæè¿°çš„ç»“æœï¼š

```json
{'type': 'object',
 'properties': {'result': {'title': 'Result',
   'description': 'the translated value',
   'type': 'string'}},
 'required': ['result']}
```

äºæ˜¯æˆ‘ä»¬çš„functionåªéœ€è¦å†™æˆè¿™æ ·å°±å¯ä»¥äº†ï¼š

```python
functions=[
            {
                "name": "print_translation",
                "description": "print the translated value from value of res",
                "parameters": ResponseSchema.schema_json(),
            },
        ]
```

åœ¨è¿™ä¸ªfunctionä¸­ï¼Œæˆ‘ä»¬çš„`print_translation` å‡½æ•°å…¶å®æ˜¯**è™šå‡çš„å‡½æ•°**ï¼Œæˆ‘ä»¬åªæ˜¯ç»™ä»–èµ·äº†ä¸€ä¸ª**åˆç†çš„åå­—ä»¥åŠåˆç†çš„æè¿°**ï¼Œè¿™æ ·GPTå°±å¯ä»¥çŸ¥é“æˆ‘ä»¬çš„å‚æ•°çš„ä¸Šä¸‹æ–‡æ˜¯ä»€ä¹ˆæ ·çš„äº†ã€‚

å®Œæ•´çš„ä¸€ä¸ªflowå¦‚ä¸‹ï¼š

```python
import openai
from pydantic import BaseModel, Field
import json


def completion(model_name, prompt):
  completion = openai.ChatCompletion.create(
            stream=False,
            model=model_name,
            messages=[
                {"role": "user", "content": prompt}
            ]
        )


  return completion.choices[0].message

class ResponseSchema(BaseModel):
    result: str = Field(..., description="the translated value")

    @classmethod
    def schema(cls, by_alias=True):
        schema = super().schema(by_alias)
        schema.pop('title', None)
        return schema
    @classmethod
    def schema_json(cls, by_alias=True, **dumps_kwargs):

        schema_str = json.dumps(cls.schema(by_alias), **dumps_kwargs)
        return json.loads(schema_str)

###  è®©GPTå¸®æˆ‘ç”Ÿæˆå¯¹åº”è¯­å¥çš„ç¿»è¯‘ï¼Œå¹¶è¿”å›æˆjson
prompt_template = """
 Now you have to translate the following text into {lang}:
    ### Text to translate:
    {text}
    ### Target language:
    {lang}
    ### Output format:
    your translation should in the following format:
    {{'res': 'your translation'}}
"""


text = 'Collection of Open Source Projects Related to GPTï¼ŒGPTç›¸å…³å¼€æºé¡¹ç›®åˆé›†ğŸš€ã€ç²¾é€‰ğŸ”¥ğŸ”¥'
lang = 'en'

functions=[
            {
                "name": "print_translation",
                "description": "print the translated value from value of res",
                "parameters": ResponseSchema.schema_json(),
            },
       ]

prompt = prompt_template.format(text=text, lang=lang)
response = completion(model_name="gpt-3.5-turbo-0613", prompt=prompt)
final_result = openai.ChatCompletion.create(
		model="gpt-3.5-turbo-0613",
		messages=[{"role": "user", "content": prompt}],
		functions=functions,
        function_call="auto",
    )
message = final_result["choices"][0]["message"]
eval(message['function_call']['arguments'])['result']

"""
æœ€ç»ˆè¾“å‡ºï¼š
Collection of Open Source Projects Related to GPT, GPT Related Open Source Project Collection ğŸš€, Selected ğŸ”¥ğŸ”¥
"""

```



## æ€»ç»“

åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æ·±å…¥æ¢ç´¢äº†OpenAIçš„å‡½æ•°è°ƒç”¨ç‰¹æ€§ï¼Œå¹¶è§£æäº†å…¶åœ¨å®ç°ç»“æ„åŒ–æ•°æ®ç”Ÿæˆä¸­çš„å·¨å¤§ä»·å€¼ã€‚è™½ç„¶æˆ‘ä»¬é€šå¸¸è®¤ä¸ºç”Ÿæˆæ¨¡å‹äº§ç”Ÿçš„æ•°æ®æ˜¯æ— ç»“æ„çš„ï¼Œä½†åœ¨æ–‡ç« ä¸­è¯æ˜ï¼Œå€ŸåŠ©å‡½æ•°è°ƒç”¨ç‰¹æ€§ï¼Œæˆ‘ä»¬å®Œå…¨æœ‰å¯èƒ½åˆ›å»ºå‡ºç»“æ„åŒ–çš„æ•°æ®ã€‚

é€šè¿‡ç¼–ç¨‹ç¤ºä¾‹ï¼Œæˆ‘ä»¬è¯¦ç»†è§£é‡Šäº†å‡½æ•°è°ƒç”¨çš„å·¥ä½œåŸç†ï¼ŒåŒ…æ‹¬å¦‚ä½•å‘GPTæ¥å£æäº¤å¸¦æœ‰é—®é¢˜å’Œå‡½æ•°è°ƒç”¨çš„è¯·æ±‚ï¼Œå¦‚ä½•åˆ©ç”¨æ¨¡å‹æå–å‡ºçš„ä¿¡æ¯å»è¯·æ±‚ç¬¬ä¸‰æ–¹æ¥å£è·å–å®æ—¶æ•°æ®ï¼Œä»¥åŠå¦‚ä½•ç”Ÿæˆä¸€ä¸ªå…¨æ–°çš„æ€»ç»“ã€‚

æ¥ç€ï¼Œæˆ‘ä»¬å±•ç¤ºäº†å¦‚ä½•å€ŸåŠ©å‡½æ•°è°ƒç”¨ç‰¹æ€§å®ç°æœºå™¨ç¿»è¯‘åŠŸèƒ½ï¼Œå¹¶ç»“æ„åŒ–è¾“å‡ºç¿»è¯‘çš„ä¿¡æ¯ã€‚æœ¬æ–‡å‘å¤§å®¶å±•ç¤ºäº†ï¼Œé€šè¿‡ä¸ºè™šæ‹Ÿå‡½æ•°å®šä¹‰åˆç†çš„åå­—å’Œæè¿°ï¼ŒGPTæ¨¡å‹èƒ½å¤Ÿç†è§£å‚æ•°çš„ä¸Šä¸‹æ–‡ï¼Œå¹¶æŒ‰ç…§é¢„è®¾çš„æ ¼å¼ç”Ÿæˆç»“æ„åŒ–çš„ç¿»è¯‘ç»“æœã€‚

æ€»çš„æ¥è¯´ï¼Œæœ¬æ–‡ä¸ºå¤§å®¶æä¾›äº†ä¸€ä¸ªå®ç”¨çš„ã€ç»“æ„åŒ–çš„æ•°æ®ç”Ÿæˆæ–¹æ³•ï¼Œå¸Œæœ›è¿™å¯¹äºæ‚¨åœ¨å¤§è§„æ¨¡æ¨¡å‹çš„æ•°æ®è§£æä»¥åŠå¤šæ ·åŒ–çš„ä¿¡æ¯æå–ä¸Šèƒ½å¤Ÿå¸¦æ¥å®è´¨æ€§çš„å¸®åŠ©ã€‚